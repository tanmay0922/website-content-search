# ğŸŒ Website Content Search Tool

A powerful full-stack application that lets users **search website content** semantically. Enter a URL, extract content intelligently, chunk and embed it, then perform semantic search using Sentence Transformers â€“ all in one seamless UI.

---

## ğŸš€ Features

- ğŸ”— Extracts content from a webpage using `BeautifulSoup`
- ğŸ“„ Splits content into 500-token chunks for efficient search
- ğŸ§  Embeds content using `SentenceTransformers`
- ğŸ” Performs semantic similarity search for user queries
- ğŸ§° Built with **FastAPI** (Backend) & **Next.js + TailwindCSS** (Frontend)

---

## ğŸ§± Tech Stack

| Layer     | Technology               |
|-----------|--------------------------|
| Frontend  | Next.js, TailwindCSS     |
| Backend   | FastAPI, Python          |
| NLP       | SentenceTransformers     |
| Parsing   | BeautifulSoup, Requests  |
| State     | React Hooks              |

---

## ğŸ“ Project Structure

website-content-search/
â”‚
â”œâ”€â”€ backend/ # FastAPI backend

â”‚ â”œâ”€â”€ main.py # API endpoints

â”‚ â”œâ”€â”€ chunker.py # Tokenizer + chunk logic

â”‚ â”œâ”€â”€ parser.py # HTML parsing

â”‚ â”œâ”€â”€ vector_db.py # In-memory embedding + search

â”‚ â””â”€â”€ requirements.txt # Python dependencies

â”‚
â”œâ”€â”€ frontend/ # Next.js frontend

â”‚ â”œâ”€â”€ app/ # Components, pages

â”‚ â”œâ”€â”€ public/ # Icons and static files

â”‚ â”œâ”€â”€ tailwind.config.js

â”‚ â”œâ”€â”€ postcss.config.js

â”‚ â”œâ”€â”€ package.json

â”‚ â””â”€â”€ next.config.mjs

â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### ğŸ Backend (FastAPI)

1. Navigate to backend folder:
2. 
   cd backend
   
2.Create virtual environment:

python -m venv venv

source venv/bin/activate  # or venv\Scripts\activate on Windows

3.Install dependencies:

pip install -r requirements.txt

4.Start FastAPI server:

uvicorn main:app --reload
ğŸŒ Frontend (Next.js)

1.Navigate to frontend folder:
cd frontend

2.Install dependencies:

npm install

3.Run the development server:

npm run dev

4.Open in browser: http://localhost:3000


ğŸ” How It Works
1.User enters a website URL and a query.

2.Backend fetches and parses the website using BeautifulSoup.

3.Text is split into meaningful 500-token chunks.

4.Chunks are embedded using a transformer model.

5.Query is embedded and matched against chunks using cosine similarity.

6.Results are ranked and displayed with context.


